import requests
import numpy as np
from typing import List
import os

# é…ç½® Embedding æœåŠ¡åœ°å€
EMBEDDING_SERVICE_URL = os.getenv("EMBEDDING_SERVICE_URL", "http://localhost:8003/embed")

def get_embeddings(texts: List[str]) -> dict:
    """æ‰¹é‡è·å–æ–‡æœ¬å‘é‡"""
    try:
        response = requests.post(EMBEDDING_SERVICE_URL, json={"input": texts})
        response.raise_for_status()
        embeddings = response.json()["embeddings"]
        return dict(zip(texts, embeddings))
    except Exception as e:
        print(f"Error fetching embeddings: {e}")
        return {}

def cosine_similarity(v1: np.ndarray, v2: np.ndarray) -> float:
    """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
    norm1 = np.linalg.norm(v1)
    norm2 = np.linalg.norm(v2)
    if norm1 == 0 or norm2 == 0:
        return 0.0
    return np.dot(v1, v2) / (norm1 * norm2)

def test_analogy():
    print("==================================================")
    print("   Embedding è¯­ä¹‰å…³ç³»æµ‹è¯• (King - Man + Woman = ?)   ")
    print("==================================================\n")

    # 1. å®šä¹‰è¯æ±‡
    words = ["king", "man", "woman", "queen", "princess", "prince", "apple", "doctor"]
    print(f"[1] è·å–è¯å‘é‡: {words} ...")
    
    vectors_map = get_embeddings(words)
    if not vectors_map:
        print("âŒ æ— æ³•è·å–å‘é‡ï¼Œè¯·ç¡®ä¿ embedding_service.py æ­£åœ¨è¿è¡Œ (ç«¯å£ 8003)ã€‚")
        return

    # è½¬æ¢ä¸º numpy æ•°ç»„ä»¥ä¾¿è®¡ç®—
    vecs = {k: np.array(v) for k, v in vectors_map.items()}

    # 2. æ‰§è¡Œå‘é‡è¿ç®—: King - Man + Woman
    # ç†è®ºä¸Šåº”è¯¥æ¥è¿‘ Queen
    print("[2] æ‰§è¡Œå‘é‡è¿ç®—: vec(king) - vec(man) + vec(woman) ...")
    target_vec = vecs["king"] - vecs["man"] + vecs["woman"]
    print(f"{vecs["king"]}, {vecs["man"]}, {vecs["woman"]}, {vecs["queen"]} = {target_vec}")

    # 3. è®¡ç®—ä¸å€™é€‰è¯çš„ç›¸ä¼¼åº¦s
    print("[3] è®¡ç®—ç›¸ä¼¼åº¦æ’å:")
    
    similarities = []
    for word, vec in vecs.items():
        print(f"    {word}")
        # è·³è¿‡å‚ä¸è¿ç®—çš„è¯ï¼Œé¿å…å¹²æ‰°ï¼ˆè™½ç„¶é€šå¸¸æˆ‘ä»¬çœ‹çš„æ˜¯ target ä¸ç»“æœçš„è·ç¦»ï¼‰
        # è¿™é‡Œä¸ºäº†ç›´è§‚ï¼Œæˆ‘ä»¬åˆ—å‡ºæ‰€æœ‰å€™é€‰è¯
        sim = cosine_similarity(target_vec, vec)
        similarities.append((word, sim))
    
    # æŒ‰ç›¸ä¼¼åº¦é™åºæ’åˆ—
    similarities.sort(key=lambda x: x[1], reverse=True)

    # 4. æ‰“å°ç»“æœ
    for rank, (word, sim) in enumerate(similarities, 1):
        indicator = "   "
        if word == "queen":
            indicator = "ğŸ‘‰ " # é¢„æœŸç›®æ ‡
        print(f"   {rank}. {indicator}{word:<10} : {sim:.4f}")

    # 5. éªŒè¯ç»“è®º
    top_word = similarities[0][0]
    queen_rank = next(i for i, (w, s) in enumerate(similarities) if w == "queen") + 1
    
    print("\n--------------------------------------------------")
    if top_word == "queen":
        print("âœ… æµ‹è¯•é€šè¿‡: 'queen' æ˜¯æœ€æ¥è¿‘è®¡ç®—ç»“æœçš„è¯å‘é‡ï¼")
    elif queen_rank <= 3:
        print(f"âš ï¸ æµ‹è¯•å°šå¯: 'queen' æ’åœ¨ç¬¬ {queen_rank} ä½ (Top 1 æ˜¯ '{top_word}')ã€‚")
        print("   è¯´æ˜: å¥å­çº§ Embedding æ¨¡å‹åœ¨è¯æ±‡çº§ç±»æ¯”æ¨ç†ä¸Šå¯èƒ½ä¸å¦‚ä¸“ç”¨è¯å‘é‡(å¦‚ Word2Vec)ç²¾å‡†ã€‚")
    else:
        print(f"âŒ æµ‹è¯•å¤±è´¥: 'queen' æ’åœ¨ç¬¬ {queen_rank} ä½ã€‚")
    print("--------------------------------------------------")

if __name__ == "__main__":
    test_analogy()
