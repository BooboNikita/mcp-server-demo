from typing import TypedDict, Annotated
from langgraph.graph.message import add_messages

import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from youdotcom import You

from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver


class SearchState(TypedDict):
    messages: Annotated[list, add_messages]
    user_query: str      # ç»è¿‡LLMç†è§£åçš„ç”¨æˆ·éœ€æ±‚æ€»ç»“
    search_query: str    # ä¼˜åŒ–åç”¨äºTavily APIçš„æœç´¢æŸ¥è¯¢
    search_results: str  # Tavilyæœç´¢è¿”å›çš„ç»“æœ
    final_answer: str    # æœ€ç»ˆç”Ÿæˆçš„ç­”æ¡ˆ
    step: str            # æ ‡è®°å½“å‰æ­¥éª¤

load_dotenv()

# åˆå§‹åŒ–æ¨¡å‹
# æˆ‘ä»¬å°†ä½¿ç”¨è¿™ä¸ª llm å®ä¾‹æ¥é©±åŠ¨æ‰€æœ‰èŠ‚ç‚¹çš„æ™ºèƒ½
KIMI_API_KEY = os.getenv("KIMI_API_KEY")
KIMI_API_URL = os.getenv("KIMI_API_URL")

llm = ChatOpenAI(
    model_name="kimi-latest",
    openai_api_key=KIMI_API_KEY,
    openai_api_base=KIMI_API_URL,
    temperature=0.7
)
# åˆå§‹åŒ–You.comå®¢æˆ·ç«¯
YOU_API_KEY = os.getenv("TAVILY_API_KEY")  # ä½¿ç”¨ç›¸åŒçš„API keyå˜é‡å
if YOU_API_KEY and YOU_API_KEY.startswith("ydc-sk-"):
    try:
        you_client = You(YOU_API_KEY)
        print(f"âœ… You.comå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸  You.comå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        you_client = None
else:
    you_client = None
    if YOU_API_KEY:
        print(f"âš ï¸  You.com API keyæ ¼å¼ä¸æ­£ç¡®ï¼ŒæœŸæœ›ä»¥'ydc-sk-'å¼€å¤´ï¼Œä½†å¾—åˆ°ï¼š{YOU_API_KEY[:10]}...")
    else:
        print("âš ï¸  You.com API keyæœªè®¾ç½®")

def understand_query_node(state: SearchState) -> dict:
    """æ­¥éª¤1ï¼šç†è§£ç”¨æˆ·æŸ¥è¯¢å¹¶ç”Ÿæˆæœç´¢å…³é”®è¯"""
    user_message = state["messages"][-1].content
    
    # ä½¿ç”¨LangGraphåŸç”Ÿæ¶ˆæ¯å†å²ï¼ˆçª—å£è®¾ä¸ºæœ€è¿‘5æ¡æ¶ˆæ¯ï¼‰
    messages = state["messages"]
    recent_messages = messages[-5:] if len(messages) > 5 else messages
    
    # æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
    history_context = ""
    if len(recent_messages) > 1:  # å¦‚æœæœ‰å†å²æ¶ˆæ¯
        history_context = "ä¹‹å‰çš„å¯¹è¯å†å²ï¼ˆæœ€è¿‘5æ¡æ¶ˆæ¯ï¼‰ï¼š\n"
        for i, msg in enumerate(recent_messages[:-1], 1):  # æ’é™¤å½“å‰æ¶ˆæ¯
            role = "ç”¨æˆ·" if isinstance(msg, HumanMessage) else "åŠ©æ‰‹"
            content = msg.content[:100] + "..." if len(msg.content) > 100 else msg.content
            history_context += f"{i}. {role}ï¼š{content}\n"
        history_context += "\n"
    
    understand_prompt = f"""{history_context}å½“å‰ç”¨æˆ·æŸ¥è¯¢ï¼š"{user_message}"

è¯·å®Œæˆä¸¤ä¸ªä»»åŠ¡ï¼š
1. ç®€æ´æ€»ç»“ç”¨æˆ·æƒ³è¦äº†è§£ä»€ä¹ˆï¼ˆç»“åˆå¯¹è¯å†å²ç†è§£ä¸Šä¸‹æ–‡ï¼‰
2. ç”Ÿæˆæœ€é€‚åˆæœç´¢å¼•æ“çš„å…³é”®è¯ï¼ˆä¸­è‹±æ–‡å‡å¯ï¼Œè¦ç²¾å‡†ï¼‰

æ ¼å¼ï¼š
ç†è§£ï¼š[ç”¨æˆ·éœ€æ±‚æ€»ç»“]
æœç´¢è¯ï¼š[æœ€ä½³æœç´¢å…³é”®è¯]"""

    response = llm.invoke([SystemMessage(content=understand_prompt)])
    response_text = response.content
    
    # è§£æLLMçš„è¾“å‡ºï¼Œæå–æœç´¢å…³é”®è¯
    search_query = user_message # é»˜è®¤ä½¿ç”¨åŸå§‹æŸ¥è¯¢
    if "æœç´¢è¯ï¼š" in response_text:
        search_query = response_text.split("æœç´¢è¯ï¼š")[1].strip()
    
    return {
        "user_query": response_text,
        "search_query": search_query,
        "step": "understood",
        "messages": [AIMessage(content=f"æˆ‘å°†ä¸ºæ‚¨æœç´¢ï¼š{search_query}")]
    }

def you_search_node(state: SearchState) -> dict:
    """æ­¥éª¤2ï¼šä½¿ç”¨You.com APIè¿›è¡ŒçœŸå®æœç´¢"""
    search_query = state["search_query"]
    try:
        print(f"ğŸ” æ­£åœ¨æœç´¢: {search_query}")
        
        # æ£€æŸ¥You.comå®¢æˆ·ç«¯æ˜¯å¦å·²åˆå§‹åŒ–
        if not you_client:
            print("âš ï¸  You.comå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œå°†ä½¿ç”¨LLMçŸ¥è¯†åº“å›ç­”")
            return {
                "search_results": "You.com APIé…ç½®é—®é¢˜ï¼Œå°†ä½¿ç”¨LLMçŸ¥è¯†åº“å›ç­”",
                "step": "search_failed",
                "messages": [AIMessage(content="âš ï¸  You.com APIé…ç½®é—®é¢˜ï¼Œå°†ä½¿ç”¨æˆ‘çš„çŸ¥è¯†åº“å›ç­”...")]
            }
        
        # ä½¿ç”¨You.comç»Ÿä¸€æœç´¢API
        response = you_client.search.unified(query=search_query, count=5)
        
        # å¤„ç†å’Œæ ¼å¼åŒ–æœç´¢ç»“æœ
        search_results = ""
        
        # å¤„ç†ç½‘é¡µæœç´¢ç»“æœ
        if hasattr(response, 'results') and hasattr(response.results, 'web'):
            for i, result in enumerate(response.results.web, 1):
                title = getattr(result, 'title', '')
                description = getattr(result, 'description', '')
                url = getattr(result, 'url', '')
                search_results += f"{i}. {title}\n{description}\næ¥æº: {url}\n\n"
        
        # å¤„ç†æ–°é—»æœç´¢ç»“æœ
        if hasattr(response, 'results') and hasattr(response.results, 'news'):
            if response.results.news:
                search_results += "\nğŸ“° ç›¸å…³æ–°é—»:\n"
                for i, result in enumerate(response.results.news, 1):
                    title = getattr(result, 'title', '')
                    description = getattr(result, 'description', '')
                    url = getattr(result, 'url', '')
                    search_results += f"{i}. {title}\n{description}\næ¥æº: {url}\n\n"
        
        if not search_results:
            search_results = "æœªæ‰¾åˆ°ç›¸å…³æœç´¢ç»“æœ"

        print('search_result', search_results)
        
        return {
            "search_results": search_results,
            "step": "searched",
            "messages": [AIMessage(content="âœ… æœç´¢å®Œæˆï¼æ­£åœ¨æ•´ç†ç­”æ¡ˆ...")]
        }
    except Exception as e:
        import traceback
        error_msg = f"æœç´¢å¤±è´¥ï¼š{e}"
        print(f"âŒ {error_msg}")
        print("ğŸ’¡ å°†ä½¿ç”¨LLMçŸ¥è¯†åº“ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
        traceback.print_exc()
        return {
            "search_results": error_msg,
            "step": "search_failed",
            "messages": [AIMessage(content="âŒ æœç´¢é‡åˆ°é—®é¢˜...")]
        }

def generate_answer_node(state: SearchState) -> dict:
    """æ­¥éª¤3ï¼šåŸºäºæœç´¢ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
    if state["step"] == "search_failed":
        # å¦‚æœæœç´¢å¤±è´¥ï¼Œæ‰§è¡Œå›é€€ç­–ç•¥ï¼ŒåŸºäºLLMè‡ªèº«çŸ¥è¯†å›ç­”
        fallback_prompt = f"æœç´¢APIæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·åŸºäºæ‚¨çš„çŸ¥è¯†å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š\nç”¨æˆ·é—®é¢˜ï¼š{state['user_query']}"
        response = llm.invoke([SystemMessage(content=fallback_prompt)])
    else:
        # æœç´¢æˆåŠŸï¼ŒåŸºäºæœç´¢ç»“æœç”Ÿæˆç­”æ¡ˆ
        answer_prompt = f"""åŸºäºä»¥ä¸‹æœç´¢ç»“æœä¸ºç”¨æˆ·æä¾›å®Œæ•´ã€å‡†ç¡®çš„ç­”æ¡ˆï¼š
ç”¨æˆ·é—®é¢˜ï¼š{state['user_query']}
æœç´¢ç»“æœï¼š\n{state['search_results']}
è¯·ç»¼åˆæœç´¢ç»“æœï¼Œæä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”..."""
        print(f"ğŸ”§ æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...æç¤ºè¯ï¼š\n{answer_prompt}")
        response = llm.invoke([SystemMessage(content=answer_prompt)])
    
    return {
        "final_answer": response.content,
        "step": "completed",
        "messages": [AIMessage(content=response.content)]
    }

def create_search_assistant():
    workflow = StateGraph(SearchState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("understand", understand_query_node)
    workflow.add_node("search", you_search_node)
    workflow.add_node("answer", generate_answer_node)
    
    # è®¾ç½®çº¿æ€§æµç¨‹
    workflow.add_edge(START, "understand")
    workflow.add_edge("understand", "search")
    workflow.add_edge("search", "answer")
    workflow.add_edge("answer", END)
    
    # ç¼–è¯‘å›¾
    memory = InMemorySaver()
    app = workflow.compile(checkpointer=memory)
    return app


async def main():
    """ä¸»å‡½æ•°ï¼šè¿è¡Œæœç´¢åŠ©æ‰‹"""
    print("ğŸš€ åˆå§‹åŒ–æœç´¢åŠ©æ‰‹...")
    app = create_search_assistant()
    
    # æ£€æŸ¥You.com API keyçŠ¶æ€
    if not YOU_API_KEY:
        print("âš ï¸  You.com API keyæœªè®¾ç½®ï¼Œæœç´¢åŠŸèƒ½å°†ä½¿ç”¨LLMçŸ¥è¯†åº“")
    else:
        print("âœ… You.com API keyå·²è®¾ç½®ï¼Œå°†ä½¿ç”¨å®æ—¶æœç´¢åŠŸèƒ½")
    
    print("âœ… æœç´¢åŠ©æ‰‹å·²å°±ç»ªï¼è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆè¾“å…¥ 'exit' æˆ– 'quit' é€€å‡ºï¼‰")
    print("ğŸ’¡ æç¤ºï¼šæˆ‘ä¼šé€šè¿‡ LangGraph åŸç”Ÿ Memory è®°ä½æœ€è¿‘ 5 æ¡æ¶ˆæ¯çš„ä¸Šä¸‹æ–‡")
    
    while True:
        try:
            user_input = input("\nğŸ” è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ > ").strip()
            
            if user_input.lower() in ["exit", "quit"]:
                print("ğŸ‘‹ å†è§ï¼")
                break
                
            if not user_input:
                continue
            
            # åˆ›å»ºåˆå§‹çŠ¶æ€
            initial_state = {
                "messages": [HumanMessage(content=user_input)],
                "user_query": "",
                "search_query": "",
                "search_results": "",
                "final_answer": "",
                "step": "start"
            }
            
            # è¿è¡Œå·¥ä½œæµ
            print("\nğŸ¤” æ­£åœ¨å¤„ç†æ‚¨çš„é—®é¢˜...")
            final_state = await app.ainvoke(initial_state, config={"configurable": {"thread_id": "1"}})
            
            # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
            print(f"\nğŸ’¡ ç­”æ¡ˆï¼š{final_state['final_answer']}")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‘ç”Ÿé”™è¯¯ï¼š{e}")


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())

